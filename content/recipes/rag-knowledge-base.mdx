---
title: RAG Knowledge Base
description: Give your avatar domain-specific knowledge using retrieval-augmented generation.
tags: [rag, turnkey, tools, intermediate]
difficulty: intermediate
sdk: javascript
date: 2025-01-17
author: Anam Team
---

# RAG Knowledge Base

RAG (Retrieval-Augmented Generation) lets your avatar answer questions using your documents instead of making things up.

## Method 1: Anam's built-in knowledge tool

Use Anam's managed knowledge base:

### Step 1: Create a knowledge group

```typescript
const response = await fetch('https://api.anam.ai/v1/knowledge/groups', {
  method: 'POST',
  headers: {
    'Content-Type': 'application/json',
    'Authorization': `Bearer ${process.env.ANAM_API_KEY}`,
  },
  body: JSON.stringify({
    name: 'Product Documentation',
    description: 'Company product docs and FAQs',
  }),
});

const { id: groupId } = await response.json();
```

### Step 2: Upload documents

Upload your knowledge documents (PDF, TXT, MD, DOCX, CSV up to 50MB):

```typescript
const formData = new FormData();
formData.append('file', documentFile);

await fetch(`https://api.anam.ai/v1/knowledge/groups/${groupId}/documents`, {
  method: 'POST',
  headers: {
    'Authorization': `Bearer ${process.env.ANAM_API_KEY}`,
  },
  body: formData,
});
```

### Step 3: Create a knowledge tool

Link the knowledge group to a tool that your persona can use:

```typescript
const tool = await fetch('https://api.anam.ai/v1/tools', {
  method: 'POST',
  headers: {
    'Content-Type': 'application/json',
    'Authorization': `Bearer ${process.env.ANAM_API_KEY}`,
  },
  body: JSON.stringify({
    name: 'search_docs',
    type: 'SERVER_RAG',
    description: 'Search product documentation to answer customer questions',
    config: {
      documentFolderIds: [groupId], // Array of knowledge group IDs to search
    },
  }),
});
```

### Step 4: Attach to your persona

Attach the tool to your persona in Anam Lab, or include it in your session token:

```typescript
// Include the tool when creating a session token
const response = await fetch('https://api.anam.ai/v1/auth/session-token', {
  method: 'POST',
  headers: {
    'Content-Type': 'application/json',
    'Authorization': `Bearer ${process.env.ANAM_API_KEY}`,
  },
  body: JSON.stringify({
    personaConfig: {
      type: 'stateful',
      personaId: 'your-persona-id',
    },
  }),
});
```

<Tip>
Update your persona's system prompt in Anam Lab to instruct the avatar when and how to use the knowledge tool. For example: "When answering questions about products, always use the search_docs tool to find accurate information."
</Tip>

## Method 2: Custom RAG with your own LLM

If you need more control, implement RAG yourself:

```typescript
import { createClient, AnamEvent } from '@anam-ai/js-sdk';
import { OpenAI } from 'openai';
import { Pinecone } from '@pinecone-database/pinecone';

const openai = new OpenAI();
const pinecone = new Pinecone();

async function searchKnowledge(query: string) {
  // Generate embedding for the query
  const embedding = await openai.embeddings.create({
    model: 'text-embedding-3-small',
    input: query,
  });

  // Search vector database
  const index = pinecone.Index('product-docs');
  const results = await index.query({
    vector: embedding.data[0].embedding,
    topK: 5,
    includeMetadata: true,
  });

  return results.matches.map((m) => m.metadata?.text as string);
}

// Set up custom LLM persona and initialize client
const client = createClient(sessionToken);

// Listen for user transcripts
client.addListener(AnamEvent.MESSAGE_STREAM_EVENT_RECEIVED, async (event) => {
  if (event.role !== 'user' || !event.endOfSpeech) return;

  // Retrieve relevant context
  const context = await searchKnowledge(event.content);

  // Generate response with context
  const response = await openai.chat.completions.create({
    model: 'gpt-4o',
    messages: [
      {
        role: 'system',
        content: `You are a helpful assistant. Use the following context to answer questions:

${context.join('\n\n')}

If the context doesn't contain relevant information, say you don't know.`,
      },
      { role: 'user', content: event.content },
    ],
  });

  await client.talk(response.choices[0].message.content);
});
```

## Tips

### Chunk documents well

```typescript
// Good: Semantic chunking with overlap
const chunks = splitDocument(document, {
  chunkSize: 500,    // ~500 tokens per chunk
  overlap: 50,       // Overlap for context continuity
  splitOn: 'paragraph', // Respect semantic boundaries
});
```

### Include metadata

```typescript
// Store useful metadata with each chunk
const chunkWithMetadata = {
  text: chunk,
  metadata: {
    source: 'product-manual-v2.pdf',
    page: 15,
    section: 'Troubleshooting',
    lastUpdated: '2025-01-15',
  },
};
```

### System prompt for RAG

```typescript
const systemPrompt = `You are a product support specialist.

INSTRUCTIONS:
1. Always search the knowledge base before answering product questions
2. If you find relevant information, cite the source
3. If the knowledge base doesn't have the answer, say "I don't have that information in my documentation, but I can help you contact support"
4. Never make up product specifications or features

TONE: Friendly, professional, concise`;
```

<Warning>
Tell your avatar to say "I don't know" when it can't find relevant information. Otherwise it will make things up.
</Warning>

## Testing

Test with questions that need document retrieval:

```typescript
const testQuestions = [
  'What are the product dimensions?',        // Should retrieve from docs
  'How do I reset my password?',             // Should retrieve from docs
  'What is the meaning of life?',            // Should acknowledge no relevant docs
  'Compare your product to CompetitorX',     // Should use docs if available
];

for (const question of testQuestions) {
  console.log(`Q: ${question}`);
  client.sendUserMessage(question);
  // Verify response uses knowledge base appropriately
}
```

## Next steps

- [Add webhook tools](/webhook-tools) - Let your avatar call external APIs
- [Implement caching](/rag-caching) - Cache frequent queries for faster responses
- [Monitor retrieval quality](/rag-monitoring) - Track and improve retrieval accuracy
